# =============================================================================
# Tazkiyah RAG v2 - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
# =============================================================================

# --- Ollama LLM Model ---
# Options for RTX 3080 10GB:
#   qwen3:8b (4.9GB) | llama3.1:8b (4.9GB) | mistral:7b (4.1GB)
#   gemma3:4b (3.3GB) | phi3:mini (2.3GB)
LLM_MODEL=gemma3:4b

# --- Ollama Embedding Model ---
# Options:
#   nomic-embed-text-v2-moe (958MB, 768 dims) - Best multilingual/Arabic
#   nomic-embed-text (274MB, 768 dims) - Fast, English-focused
#   mxbai-embed-large (670MB, 1024 dims) - Balanced
#   bge-m3 (1.2GB, 1024 dims) - High accuracy
EMBEDDING_MODEL=nomic-embed-text-v2-moe

# --- Ollama Server ---
OLLAMA_BASE_URL=http://localhost:11434

# --- LangSmith Tracing ---
# Get your API key from https://smith.langchain.com
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your-langsmith-api-key-here
LANGSMITH_PROJECT=tazkiyah-rag-v2
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# --- Vector Store ---
CHROMA_PERSIST_DIR=rag_v2/chroma_db_v2
COLLECTION_NAME=quran_tazkiyah_v2

# --- Retrieval ---
TOP_K=5
SEARCH_TYPE=similarity
MMR_LAMBDA=0.5
MIN_RELEVANCE_SCORE=0.0

# --- LLM Generation ---
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=1024
LLM_TOP_P=0.9
LLM_REPEAT_PENALTY=1.1

# --- Embedding Prefixes (for nomic-embed-text-v2-moe) ---
EMBED_QUERY_PREFIX=search_query: 
EMBED_DOCUMENT_PREFIX=search_document: 

# --- UI ---
UI_SERVER_HOST=127.0.0.1
UI_SERVER_PORT=7861
SHOW_SOURCES=true
MAX_SOURCES_DISPLAY=5

# --- Logging ---
LOG_LEVEL=INFO
